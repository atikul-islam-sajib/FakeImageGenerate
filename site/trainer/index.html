<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Trainer - Fake Skin Cancer Image Generator GAN</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Trainer";
        var mkdocs_page_input_path = "trainer.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Fake Skin Cancer Image Generator GAN
        </a>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../data_loader/">DataLoader</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../generator/">Generator</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../discriminator/">Discriminator</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">Trainer</a>
    <ul class="current">
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../test/">Test</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../utils/">Utils</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Fake Skin Cancer Image Generator GAN</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Trainer</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <div class="doc doc-object doc-module">



<a id="trainer"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="trainer.Trainer" class="doc doc-heading">
          <code>Trainer</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Trainer class for a Generative Adversarial Network (GAN) encapsulates the training process, including initialization, training loops for the discriminator and generator, and saving the model. It handles training over a specified number of epochs, optimizes both the generator and discriminator models, and logs training progress.</p>
<p>Parameters:
- device (torch.device): The device to train on, e.g., 'cpu' or 'cuda'.
- latent_space (int, optional): Dimension of the latent space vector. Defaults to 100.
- image_size (int, optional): Height and width of the images to generate. Defaults to 64.
- lr (float, optional): Learning rate for the Adam optimizers. Defaults to 0.0002.
- epochs (int, optional): Number of training epochs. Defaults to 100.</p>
<p>Attributes:
- netG (Generator): The generator model.
- netD (Discriminator): The discriminator model.
- optimizerD (torch.optim.Optimizer): Optimizer for the discriminator.
- optimizerG (torch.optim.Optimizer): Optimizer for the generator.
- criterion (nn.Module): Loss function (Binary Cross Entropy Loss).
- real_label (float): Label for real images (1.0).
- fake_label (float): Label for fake images (0.0).
- nz (int): Size of the latent vector (z).
- num_epochs (int): Number of epochs for training.</p>
<p>Methods:
- model_init(): Initializes the models and applies weights initialization.
- optimizer_init(generator, discriminator): Initializes the optimizers for both models.
- train_discriminator(data): Performs a single training step for the discriminator.
- train_generator(fake): Performs a single training step for the generator.
- display_results(epoch, i, dataloader, errD, errG, D_x, D_G_z1, D_G_z2): Logs training progress to the console.
- save_generator_model(epoch): Saves the current state of the generator model.
- dataloader(): Loads and returns a dataloader instance.
- train(): Executes the training loop over the specified number of epochs.</p>

<details class="example" open>
  <summary>Example</summary>
  <p>device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
trainer = Trainer(device=device, epochs=30, lr=0.0002)
trainer.train()</p>
</details>      <p>Note:
This class assumes the presence of <code>Generator</code> and <code>Discriminator</code> classes, along with a <code>weights_init</code> function for model weight initialization. The dataloader is expected to be loaded using joblib from a specified path.</p>

            <details class="quote">
              <summary>Source code in <code>trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trainer class for a Generative Adversarial Network (GAN) encapsulates the training process, including initialization, training loops for the discriminator and generator, and saving the model. It handles training over a specified number of epochs, optimizes both the generator and discriminator models, and logs training progress.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - device (torch.device): The device to train on, e.g., &#39;cpu&#39; or &#39;cuda&#39;.</span>
<span class="sd">    - latent_space (int, optional): Dimension of the latent space vector. Defaults to 100.</span>
<span class="sd">    - image_size (int, optional): Height and width of the images to generate. Defaults to 64.</span>
<span class="sd">    - lr (float, optional): Learning rate for the Adam optimizers. Defaults to 0.0002.</span>
<span class="sd">    - epochs (int, optional): Number of training epochs. Defaults to 100.</span>

<span class="sd">    Attributes:</span>
<span class="sd">    - netG (Generator): The generator model.</span>
<span class="sd">    - netD (Discriminator): The discriminator model.</span>
<span class="sd">    - optimizerD (torch.optim.Optimizer): Optimizer for the discriminator.</span>
<span class="sd">    - optimizerG (torch.optim.Optimizer): Optimizer for the generator.</span>
<span class="sd">    - criterion (nn.Module): Loss function (Binary Cross Entropy Loss).</span>
<span class="sd">    - real_label (float): Label for real images (1.0).</span>
<span class="sd">    - fake_label (float): Label for fake images (0.0).</span>
<span class="sd">    - nz (int): Size of the latent vector (z).</span>
<span class="sd">    - num_epochs (int): Number of epochs for training.</span>

<span class="sd">    Methods:</span>
<span class="sd">    - model_init(): Initializes the models and applies weights initialization.</span>
<span class="sd">    - optimizer_init(generator, discriminator): Initializes the optimizers for both models.</span>
<span class="sd">    - train_discriminator(data): Performs a single training step for the discriminator.</span>
<span class="sd">    - train_generator(fake): Performs a single training step for the generator.</span>
<span class="sd">    - display_results(epoch, i, dataloader, errD, errG, D_x, D_G_z1, D_G_z2): Logs training progress to the console.</span>
<span class="sd">    - save_generator_model(epoch): Saves the current state of the generator model.</span>
<span class="sd">    - dataloader(): Loads and returns a dataloader instance.</span>
<span class="sd">    - train(): Executes the training loop over the specified number of epochs.</span>

<span class="sd">    Example:</span>
<span class="sd">        device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="sd">        trainer = Trainer(device=device, epochs=30, lr=0.0002)</span>
<span class="sd">        trainer.train()</span>

<span class="sd">    Note:</span>
<span class="sd">    This class assumes the presence of `Generator` and `Discriminator` classes, along with a `weights_init` function for model weight initialization. The dataloader is expected to be loaded using joblib from a specified path.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="n">latent_space</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">image_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">lr</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device_init</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nz</span> <span class="o">=</span> <span class="n">latent_space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">display</span> <span class="o">=</span> <span class="n">display</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_init</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exception caught in model initialization # </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="s2">&quot;Model initialization error # </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">netG</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">netD</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizerD</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizerG</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_init</span><span class="p">(</span>
                <span class="n">generator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="p">,</span> <span class="n">discriminator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">netD</span>
            <span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">real_label</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fake_label</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">model_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the Generator and Discriminator models for the GAN. This method constructs the models with the specified latent space size and image size, moves them to the appropriate device (CPU or GPU), and applies a predefined weight initialization function to both models.</span>

<span class="sd">        The models are defined by the Generator and Discriminator classes, which should be available in the same scope as this Trainer class. The latent space size and image size are used to configure the models according to the specifics of the GAN architecture being trained.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: A tuple containing two nn.Module objects:</span>
<span class="sd">                - netG (Generator): The initialized generator model, ready for training.</span>
<span class="sd">                - netD (Discriminator): The initialized discriminator model, ready for training.</span>

<span class="sd">        Side effects:</span>
<span class="sd">            - Instantiates the Generator and Discriminator models with the specified configurations.</span>
<span class="sd">            - Applies a predefined weight initialization function to both models to ensure optimal training behavior.</span>
<span class="sd">            - Moves the models to the specified device, which is typically determined by whether a GPU is available for training.</span>

<span class="sd">        Note:</span>
<span class="sd">            The device used for training is determined by the &#39;device&#39; attribute of the Trainer class instance. The weights initialization function applied to both models is defined externally and must be available in the same scope as this Trainer class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">netG</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">latent_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nz</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">)</span>
        <span class="n">netD</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">image_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">)</span>
        <span class="n">netG</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weight_init</span><span class="p">)</span>
        <span class="n">netD</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weight_init</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">netG</span><span class="p">,</span> <span class="n">netD</span>

    <span class="k">def</span> <span class="nf">optimizer_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">discriminator</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the optimizers for both the generator and discriminator models. This method sets up Adam optimizers with specified learning rates and betas parameters, which are critical for the training dynamics of the Generative Adversarial Network (GAN).</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - generator (torch.nn.Module): The generator model for which the optimizer will be initialized. This model should already be instantiated and configured with the appropriate architecture for generating images.</span>
<span class="sd">        - discriminator (torch.nn.Module): The discriminator model for which the optimizer will be initialized. This model should already be instantiated and configured with the appropriate architecture for discriminating between real and generated images.</span>

<span class="sd">        Returns:</span>
<span class="sd">        - tuple: A tuple containing two optimizer objects:</span>
<span class="sd">            - optimizerD (torch.optim.Adam): The Adam optimizer configured for the discriminator model, including learning rate and betas parameters.</span>
<span class="sd">            - optimizerG (torch.optim.Adam): The Adam optimizer configured for the generator model, including learning rate and betas parameters.</span>

<span class="sd">        Note:</span>
<span class="sd">        - The learning rate (`lr`) and betas parameters for the Adam optimizers are critical hyperparameters that can affect the training stability and convergence of the GAN. These parameters are set based on best practices and empirical results but may require adjustment based on the specific characteristics of the dataset or model architecture.</span>
<span class="sd">        - This method assumes that the `lr` attribute (learning rate) is already set in the Trainer class instance and uses this value for both optimizers. The betas parameters are fixed in this implementation but could be exposed as parameters or attributes for more flexibility.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">optimizerD</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
            <span class="n">params</span><span class="o">=</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">optimizerG</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
            <span class="n">params</span><span class="o">=</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">optimizerD</span><span class="p">,</span> <span class="n">optimizerG</span>

    <span class="k">def</span> <span class="nf">train_discriminator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the discriminator model on both real and generated (fake) images. This method performs a forward pass with real images from the dataset and fake images generated by the generator, computes the loss for both, backpropagates to update the discriminator&#39;s weights, and returns the losses and discriminator outputs.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - data (torch.Tensor): A batch of real images from the dataset. This tensor should have the shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and width of the images.</span>

<span class="sd">        Returns:</span>
<span class="sd">        - tuple: A tuple containing the following elements:</span>
<span class="sd">            - errD (torch.Tensor): The total discriminator loss calculated as the sum of the loss for real and fake images.</span>
<span class="sd">            - D_x (float): The mean output of the discriminator for real images. This value is used to evaluate the discriminator&#39;s performance on real data.</span>
<span class="sd">            - D_G_z1 (float): The mean output of the discriminator for fake images before the generator update. This value is used to evaluate the discriminator&#39;s performance on fake data.</span>
<span class="sd">            - fake (torch.Tensor): A batch of fake images generated by the generator.</span>

<span class="sd">        The method performs the following steps:</span>
<span class="sd">        1. Zeroes the gradients of the discriminator.</span>
<span class="sd">        2. Processes a batch of real images, computes the loss against the true labels, backpropagates the error, and calculates the mean discriminator output (D_x).</span>
<span class="sd">        3. Generates a batch of fake images using the generator, computes the loss against the false labels, backpropagates the error, and calculates the mean discriminator output for the fake images (D_G_z1).</span>
<span class="sd">        4. Updates the discriminator&#39;s weights based on the total loss.</span>

<span class="sd">        Note:</span>
<span class="sd">        - This method updates the discriminator&#39;s weights once per call, using the combined loss from both real and fake images.</span>
<span class="sd">        - The real_label and fake_label attributes of the Trainer class are used to denote the true and false labels, respectively, for computing the loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">real_cpu</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_cpu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
            <span class="p">(</span><span class="n">batch_size</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">real_label</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">real_cpu</span><span class="p">)</span>
        <span class="n">errD_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">errD_real</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">D_x</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nz</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
        <span class="n">label</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fake_label</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">fake</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
        <span class="n">errD_fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">errD_fake</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">D_G_z1</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">errD</span> <span class="o">=</span> <span class="n">errD_real</span> <span class="o">+</span> <span class="n">errD_fake</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizerD</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">errD</span><span class="p">,</span> <span class="n">D_x</span><span class="p">,</span> <span class="n">D_G_z1</span><span class="p">,</span> <span class="n">fake</span>

    <span class="k">def</span> <span class="nf">train_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fake</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the generator model by attempting to fool the discriminator.</span>

<span class="sd">        This method updates the generator&#39;s weights based on its ability to generate fake images that the discriminator classifies as real. It computes the loss using the output of the discriminator on the generated (fake) images, performs backpropagation to calculate the gradients, and updates the generator&#39;s weights to reduce this loss.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - fake (torch.Tensor): A batch of fake images generated by the generator model. The tensor should have dimensions (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and width of the images, respectively.</span>

<span class="sd">        Returns:</span>
<span class="sd">        - tuple: A tuple containing the following elements:</span>
<span class="sd">            - errG (torch.Tensor): The loss of the generator computed as the binary cross-entropy loss between the discriminator&#39;s output on the fake images and the real labels.</span>
<span class="sd">            - D_G_z2 (float): The average output of the discriminator for the fake images. This metric indicates how well the generator is fooling the discriminator, with higher values suggesting better performance.</span>

<span class="sd">        The training step involves:</span>
<span class="sd">        1. Zeroing the gradients of the generator to ensure that previous training steps do not affect the current update.</span>
<span class="sd">        2. Creating a tensor of real labels (since the generator&#39;s goal is to have its fake images classified as real by the discriminator) and computing the loss against the discriminator&#39;s predictions on the fake images.</span>
<span class="sd">        3. Performing backpropagation to calculate the gradients with respect to the generator&#39;s parameters.</span>
<span class="sd">        4. Updating the generator&#39;s weights using the optimizer to reduce the loss, thereby improving the generator&#39;s ability to produce realistic images.</span>

<span class="sd">        Note:</span>
<span class="sd">        - The method assumes the use of the binary cross-entropy loss (BCELoss) to quantify how well the generator is fooling the discriminator. The labels for the fake images are set to &#39;real&#39; (self.real_label) for the purpose of this loss calculation.</span>
<span class="sd">        - This method directly influences the generator&#39;s performance by adjusting its ability to create images that are indistinguishable from real images to the discriminator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
            <span class="p">(</span><span class="n">fake</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),),</span> <span class="bp">self</span><span class="o">.</span><span class="n">real_label</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">fake</span><span class="p">)</span>
        <span class="n">errG</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">errG</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">D_G_z2</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizerG</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">errG</span><span class="p">,</span> <span class="n">D_G_z2</span>

    <span class="k">def</span> <span class="nf">display_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">errD</span><span class="p">,</span> <span class="n">errG</span><span class="p">,</span> <span class="n">D_x</span><span class="p">,</span> <span class="n">D_G_z1</span><span class="p">,</span> <span class="n">D_G_z2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Displays the training results and progress metrics for the current batch and epoch.</span>

<span class="sd">        This method logs the losses of the discriminator and generator, as well as the discriminator&#39;s performance on real and fake images. It provides insights into how well the discriminator and generator are learning and adapting during the training process.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - epoch (int): The current epoch number during training.</span>
<span class="sd">        - i (int): The current batch number within the epoch.</span>
<span class="sd">        - dataloader (DataLoader): The DataLoader used for training, utilized here to determine the total number of batches.</span>
<span class="sd">        - errD (float): The current loss of the discriminator.</span>
<span class="sd">        - errG (float): The current loss of the generator.</span>
<span class="sd">        - D_x (float): The average output of the discriminator for real images. Closer to 1 indicates better performance on real images.</span>
<span class="sd">        - D_G_z1 (float): The average output of the discriminator for fake images before the generator update. Closer to 0 indicates better discrimination of fake images.</span>
<span class="sd">        - D_G_z2 (float): The average output of the discriminator for fake images after the generator update. Closer to 1 indicates the generator is improving in fooling the discriminator.</span>

<span class="sd">        Output:</span>
<span class="sd">        - The method prints a formatted string to the console, summarizing the training metrics for the current batch within the ongoing epoch.</span>

<span class="sd">        Note:</span>
<span class="sd">        - This method is intended for logging purposes and does not return any values. It provides a snapshot of the training progress at the moment it is called, allowing for monitoring of the GAN&#39;s learning dynamics.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">display</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">][</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">] Loss_D: </span><span class="si">{</span><span class="n">errD</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> Loss_G: </span><span class="si">{</span><span class="n">errG</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> D(x): </span><span class="si">{</span><span class="n">D_x</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> D(G(z)): </span><span class="si">{</span><span class="n">D_G_z1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="n">D_G_z2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">][</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">] Loss_D: </span><span class="si">{</span><span class="n">errD</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> Loss_G: </span><span class="si">{</span><span class="n">errG</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> D(x): </span><span class="si">{</span><span class="n">D_x</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> D(G(z)): </span><span class="si">{</span><span class="n">D_G_z1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="n">D_G_z2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">save_generator_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves the state dictionary of the generator model to a file, capturing its current weights.</span>

<span class="sd">        This method is typically called at the end of each training epoch to persist the state of the generator model, allowing for later use or further training from the saved state. The filename includes the epoch number for easy identification and versioning.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - epoch (int): The current epoch number. This is used to name the saved model file, indicating at which point in the training process the model was saved.</span>

<span class="sd">        Output:</span>
<span class="sd">        - The method saves the generator&#39;s state dictionary to a file in the current working directory. The file is named &#39;generator_epoch_{epoch}.pth&#39;, where `{epoch}` is replaced with the current epoch number.</span>

<span class="sd">        Note:</span>
<span class="sd">        - This method does not return any value. It performs a file I/O operation to write the generator model&#39;s state dictionary to disk.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;./models/checkpoints/generator_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.pth&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;./models/best_model/generator_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.pth&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads and returns the training data loader from a serialized file.</span>

<span class="sd">        This method is responsible for loading the training data loader, which has been previously saved to disk using serialization (e.g., with joblib). It allows for quick loading of preprocessed and prepared batches of data for training.</span>

<span class="sd">        Returns:</span>
<span class="sd">        - DataLoader: The loaded DataLoader object ready for iteration. This dataloader is expected to yield batches of training data during the training loop.</span>

<span class="sd">        Note:</span>
<span class="sd">        - The dataloader is loaded from a predefined path &#39;../data/processed/dataloader.pkl&#39;. This path must exist and contain a serialized DataLoader object. The method assumes the preprocessing and preparation of data are already completed and saved to this location.</span>
<span class="sd">        - This method performs a file I/O operation to read the DataLoader object from disk. Ensure the specified path is accessible and the file format is compatible with the joblib library.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;./data/processed/dataloader.pkl&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Executes the training loop for the Generative Adversarial Network (GAN).</span>

<span class="sd">        This method orchestrates the training process by iterating over a specified number of epochs, during which it trains the discriminator and generator models in sequence. At each step of the training, it logs the progress, including the losses of both models and the discriminator&#39;s performance metrics. At the end of each epoch, it saves the current state of the generator model.</span>

<span class="sd">        The training loop follows these steps:</span>
<span class="sd">        1. Loads the data using the `dataloader` method, which should return an iterable DataLoader object containing the training data.</span>
<span class="sd">        2. Iterates over the specified number of epochs (as defined by `self.num_epochs`).</span>
<span class="sd">            a. For each batch in the DataLoader:</span>
<span class="sd">                i. Trains the discriminator on both real and fake data, computing its loss.</span>
<span class="sd">                ii. Generates a new batch of fake data and trains the generator, attempting to fool the discriminator, computing its loss.</span>
<span class="sd">                iii. Logs the current losses and discriminator performance metrics using the `display_results` method.</span>
<span class="sd">        3. Saves the state of the generator model after each epoch using the `save_generator_model` method.</span>

<span class="sd">        Note:</span>
<span class="sd">        - The actual training of the discriminator and generator is performed by the `train_discriminator` and `train_generator` methods, respectively. This method coordinates these calls and handles logging and model state saving.</span>
<span class="sd">        - Progress logging and model saving are designed to provide insights into the training process and to allow for interruption and resumption of training without loss of progress.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataloader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataloader</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">errD</span><span class="p">,</span> <span class="n">D_x</span><span class="p">,</span> <span class="n">D_G_z1</span><span class="p">,</span> <span class="n">fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_discriminator</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">errG</span><span class="p">,</span> <span class="n">D_G_z2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_generator</span><span class="p">(</span><span class="n">fake</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">display_results</span><span class="p">(</span>
                    <span class="n">epoch</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">errD</span><span class="p">,</span> <span class="n">errG</span><span class="p">,</span> <span class="n">D_x</span><span class="p">,</span> <span class="n">D_G_z1</span><span class="p">,</span> <span class="n">D_G_z2</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_generator_model</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h3 id="trainer.Trainer.dataloader" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">dataloader</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Loads and returns the training data loader from a serialized file.</p>
<p>This method is responsible for loading the training data loader, which has been previously saved to disk using serialization (e.g., with joblib). It allows for quick loading of preprocessed and prepared batches of data for training.</p>
<p>Returns:
- DataLoader: The loaded DataLoader object ready for iteration. This dataloader is expected to yield batches of training data during the training loop.</p>
<p>Note:
- The dataloader is loaded from a predefined path '../data/processed/dataloader.pkl'. This path must exist and contain a serialized DataLoader object. The method assumes the preprocessing and preparation of data are already completed and saved to this location.
- This method performs a file I/O operation to read the DataLoader object from disk. Ensure the specified path is accessible and the file format is compatible with the joblib library.</p>

          <details class="quote">
            <summary>Source code in <code>trainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads and returns the training data loader from a serialized file.</span>

<span class="sd">    This method is responsible for loading the training data loader, which has been previously saved to disk using serialization (e.g., with joblib). It allows for quick loading of preprocessed and prepared batches of data for training.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - DataLoader: The loaded DataLoader object ready for iteration. This dataloader is expected to yield batches of training data during the training loop.</span>

<span class="sd">    Note:</span>
<span class="sd">    - The dataloader is loaded from a predefined path &#39;../data/processed/dataloader.pkl&#39;. This path must exist and contain a serialized DataLoader object. The method assumes the preprocessing and preparation of data are already completed and saved to this location.</span>
<span class="sd">    - This method performs a file I/O operation to read the DataLoader object from disk. Ensure the specified path is accessible and the file format is compatible with the joblib library.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;./data/processed/dataloader.pkl&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="trainer.Trainer.display_results" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">display_results</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">errD</span><span class="p">,</span> <span class="n">errG</span><span class="p">,</span> <span class="n">D_x</span><span class="p">,</span> <span class="n">D_G_z1</span><span class="p">,</span> <span class="n">D_G_z2</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Displays the training results and progress metrics for the current batch and epoch.</p>
<p>This method logs the losses of the discriminator and generator, as well as the discriminator's performance on real and fake images. It provides insights into how well the discriminator and generator are learning and adapting during the training process.</p>
<p>Parameters:
- epoch (int): The current epoch number during training.
- i (int): The current batch number within the epoch.
- dataloader (DataLoader): The DataLoader used for training, utilized here to determine the total number of batches.
- errD (float): The current loss of the discriminator.
- errG (float): The current loss of the generator.
- D_x (float): The average output of the discriminator for real images. Closer to 1 indicates better performance on real images.
- D_G_z1 (float): The average output of the discriminator for fake images before the generator update. Closer to 0 indicates better discrimination of fake images.
- D_G_z2 (float): The average output of the discriminator for fake images after the generator update. Closer to 1 indicates the generator is improving in fooling the discriminator.</p>
<p>Output:
- The method prints a formatted string to the console, summarizing the training metrics for the current batch within the ongoing epoch.</p>
<p>Note:
- This method is intended for logging purposes and does not return any values. It provides a snapshot of the training progress at the moment it is called, allowing for monitoring of the GAN's learning dynamics.</p>

          <details class="quote">
            <summary>Source code in <code>trainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">display_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">errD</span><span class="p">,</span> <span class="n">errG</span><span class="p">,</span> <span class="n">D_x</span><span class="p">,</span> <span class="n">D_G_z1</span><span class="p">,</span> <span class="n">D_G_z2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Displays the training results and progress metrics for the current batch and epoch.</span>

<span class="sd">    This method logs the losses of the discriminator and generator, as well as the discriminator&#39;s performance on real and fake images. It provides insights into how well the discriminator and generator are learning and adapting during the training process.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - epoch (int): The current epoch number during training.</span>
<span class="sd">    - i (int): The current batch number within the epoch.</span>
<span class="sd">    - dataloader (DataLoader): The DataLoader used for training, utilized here to determine the total number of batches.</span>
<span class="sd">    - errD (float): The current loss of the discriminator.</span>
<span class="sd">    - errG (float): The current loss of the generator.</span>
<span class="sd">    - D_x (float): The average output of the discriminator for real images. Closer to 1 indicates better performance on real images.</span>
<span class="sd">    - D_G_z1 (float): The average output of the discriminator for fake images before the generator update. Closer to 0 indicates better discrimination of fake images.</span>
<span class="sd">    - D_G_z2 (float): The average output of the discriminator for fake images after the generator update. Closer to 1 indicates the generator is improving in fooling the discriminator.</span>

<span class="sd">    Output:</span>
<span class="sd">    - The method prints a formatted string to the console, summarizing the training metrics for the current batch within the ongoing epoch.</span>

<span class="sd">    Note:</span>
<span class="sd">    - This method is intended for logging purposes and does not return any values. It provides a snapshot of the training progress at the moment it is called, allowing for monitoring of the GAN&#39;s learning dynamics.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">display</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">][</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">] Loss_D: </span><span class="si">{</span><span class="n">errD</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> Loss_G: </span><span class="si">{</span><span class="n">errG</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> D(x): </span><span class="si">{</span><span class="n">D_x</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> D(G(z)): </span><span class="si">{</span><span class="n">D_G_z1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="n">D_G_z2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">][</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">] Loss_D: </span><span class="si">{</span><span class="n">errD</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> Loss_G: </span><span class="si">{</span><span class="n">errG</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> D(x): </span><span class="si">{</span><span class="n">D_x</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> D(G(z)): </span><span class="si">{</span><span class="n">D_G_z1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="n">D_G_z2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="trainer.Trainer.model_init" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">model_init</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initializes the Generator and Discriminator models for the GAN. This method constructs the models with the specified latent space size and image size, moves them to the appropriate device (CPU or GPU), and applies a predefined weight initialization function to both models.</p>
<p>The models are defined by the Generator and Discriminator classes, which should be available in the same scope as this Trainer class. The latent space size and image size are used to configure the models according to the specifics of the GAN architecture being trained.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
    <th class="field-name">Returns:</th>
    <td class="field-body">
      <ul class="first simple">
          <li>
<b><code>tuple</code></b>            –
            <div class="doc-md-description">
              <p>A tuple containing two nn.Module objects:
- netG (Generator): The initialized generator model, ready for training.
- netD (Discriminator): The initialized discriminator model, ready for training.</p>
            </div>
          </li>
      </ul>
    </td>
    </tr>
  </tbody>
</table>
<details class="side-effects" open>
  <summary>Side effects</summary>
  <ul>
<li>Instantiates the Generator and Discriminator models with the specified configurations.</li>
<li>Applies a predefined weight initialization function to both models to ensure optimal training behavior.</li>
<li>Moves the models to the specified device, which is typically determined by whether a GPU is available for training.</li>
</ul>
</details>
<details class="note" open>
  <summary>Note</summary>
  <p>The device used for training is determined by the 'device' attribute of the Trainer class instance. The weights initialization function applied to both models is defined externally and must be available in the same scope as this Trainer class.</p>
</details>
          <details class="quote">
            <summary>Source code in <code>trainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">model_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the Generator and Discriminator models for the GAN. This method constructs the models with the specified latent space size and image size, moves them to the appropriate device (CPU or GPU), and applies a predefined weight initialization function to both models.</span>

<span class="sd">    The models are defined by the Generator and Discriminator classes, which should be available in the same scope as this Trainer class. The latent space size and image size are used to configure the models according to the specifics of the GAN architecture being trained.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: A tuple containing two nn.Module objects:</span>
<span class="sd">            - netG (Generator): The initialized generator model, ready for training.</span>
<span class="sd">            - netD (Discriminator): The initialized discriminator model, ready for training.</span>

<span class="sd">    Side effects:</span>
<span class="sd">        - Instantiates the Generator and Discriminator models with the specified configurations.</span>
<span class="sd">        - Applies a predefined weight initialization function to both models to ensure optimal training behavior.</span>
<span class="sd">        - Moves the models to the specified device, which is typically determined by whether a GPU is available for training.</span>

<span class="sd">    Note:</span>
<span class="sd">        The device used for training is determined by the &#39;device&#39; attribute of the Trainer class instance. The weights initialization function applied to both models is defined externally and must be available in the same scope as this Trainer class.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">netG</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">latent_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nz</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">)</span>
    <span class="n">netD</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">image_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">)</span>
    <span class="n">netG</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weight_init</span><span class="p">)</span>
    <span class="n">netD</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weight_init</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">netG</span><span class="p">,</span> <span class="n">netD</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="trainer.Trainer.optimizer_init" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">optimizer_init</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">discriminator</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initializes the optimizers for both the generator and discriminator models. This method sets up Adam optimizers with specified learning rates and betas parameters, which are critical for the training dynamics of the Generative Adversarial Network (GAN).</p>
<p>Parameters:
- generator (torch.nn.Module): The generator model for which the optimizer will be initialized. This model should already be instantiated and configured with the appropriate architecture for generating images.
- discriminator (torch.nn.Module): The discriminator model for which the optimizer will be initialized. This model should already be instantiated and configured with the appropriate architecture for discriminating between real and generated images.</p>
      <ul>
<li>tuple: A tuple containing two optimizer objects:<ul>
<li>optimizerD (torch.optim.Adam): The Adam optimizer configured for the discriminator model, including learning rate and betas parameters.</li>
<li>optimizerG (torch.optim.Adam): The Adam optimizer configured for the generator model, including learning rate and betas parameters.</li>
</ul>
</li>
</ul>
<p>Note:
- The learning rate (<code>lr</code>) and betas parameters for the Adam optimizers are critical hyperparameters that can affect the training stability and convergence of the GAN. These parameters are set based on best practices and empirical results but may require adjustment based on the specific characteristics of the dataset or model architecture.
- This method assumes that the <code>lr</code> attribute (learning rate) is already set in the Trainer class instance and uses this value for both optimizers. The betas parameters are fixed in this implementation but could be exposed as parameters or attributes for more flexibility.</p>

          <details class="quote">
            <summary>Source code in <code>trainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">optimizer_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">discriminator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the optimizers for both the generator and discriminator models. This method sets up Adam optimizers with specified learning rates and betas parameters, which are critical for the training dynamics of the Generative Adversarial Network (GAN).</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - generator (torch.nn.Module): The generator model for which the optimizer will be initialized. This model should already be instantiated and configured with the appropriate architecture for generating images.</span>
<span class="sd">    - discriminator (torch.nn.Module): The discriminator model for which the optimizer will be initialized. This model should already be instantiated and configured with the appropriate architecture for discriminating between real and generated images.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - tuple: A tuple containing two optimizer objects:</span>
<span class="sd">        - optimizerD (torch.optim.Adam): The Adam optimizer configured for the discriminator model, including learning rate and betas parameters.</span>
<span class="sd">        - optimizerG (torch.optim.Adam): The Adam optimizer configured for the generator model, including learning rate and betas parameters.</span>

<span class="sd">    Note:</span>
<span class="sd">    - The learning rate (`lr`) and betas parameters for the Adam optimizers are critical hyperparameters that can affect the training stability and convergence of the GAN. These parameters are set based on best practices and empirical results but may require adjustment based on the specific characteristics of the dataset or model architecture.</span>
<span class="sd">    - This method assumes that the `lr` attribute (learning rate) is already set in the Trainer class instance and uses this value for both optimizers. The betas parameters are fixed in this implementation but could be exposed as parameters or attributes for more flexibility.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">optimizerD</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
        <span class="n">params</span><span class="o">=</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">optimizerG</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
        <span class="n">params</span><span class="o">=</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">optimizerD</span><span class="p">,</span> <span class="n">optimizerG</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="trainer.Trainer.save_generator_model" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">save_generator_model</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Saves the state dictionary of the generator model to a file, capturing its current weights.</p>
<p>This method is typically called at the end of each training epoch to persist the state of the generator model, allowing for later use or further training from the saved state. The filename includes the epoch number for easy identification and versioning.</p>
<p>Parameters:
- epoch (int): The current epoch number. This is used to name the saved model file, indicating at which point in the training process the model was saved.</p>
<p>Output:
- The method saves the generator's state dictionary to a file in the current working directory. The file is named 'generator_epoch_{epoch}.pth', where <code>{epoch}</code> is replaced with the current epoch number.</p>
<p>Note:
- This method does not return any value. It performs a file I/O operation to write the generator model's state dictionary to disk.</p>

          <details class="quote">
            <summary>Source code in <code>trainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_generator_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Saves the state dictionary of the generator model to a file, capturing its current weights.</span>

<span class="sd">    This method is typically called at the end of each training epoch to persist the state of the generator model, allowing for later use or further training from the saved state. The filename includes the epoch number for easy identification and versioning.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - epoch (int): The current epoch number. This is used to name the saved model file, indicating at which point in the training process the model was saved.</span>

<span class="sd">    Output:</span>
<span class="sd">    - The method saves the generator&#39;s state dictionary to a file in the current working directory. The file is named &#39;generator_epoch_{epoch}.pth&#39;, where `{epoch}` is replaced with the current epoch number.</span>

<span class="sd">    Note:</span>
<span class="sd">    - This method does not return any value. It performs a file I/O operation to write the generator model&#39;s state dictionary to disk.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;./models/checkpoints/generator_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.pth&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;./models/best_model/generator_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.pth&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="trainer.Trainer.train" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Executes the training loop for the Generative Adversarial Network (GAN).</p>
<p>This method orchestrates the training process by iterating over a specified number of epochs, during which it trains the discriminator and generator models in sequence. At each step of the training, it logs the progress, including the losses of both models and the discriminator's performance metrics. At the end of each epoch, it saves the current state of the generator model.</p>
<p>The training loop follows these steps:
1. Loads the data using the <code>dataloader</code> method, which should return an iterable DataLoader object containing the training data.
2. Iterates over the specified number of epochs (as defined by <code>self.num_epochs</code>).
    a. For each batch in the DataLoader:
        i. Trains the discriminator on both real and fake data, computing its loss.
        ii. Generates a new batch of fake data and trains the generator, attempting to fool the discriminator, computing its loss.
        iii. Logs the current losses and discriminator performance metrics using the <code>display_results</code> method.
3. Saves the state of the generator model after each epoch using the <code>save_generator_model</code> method.</p>
<p>Note:
- The actual training of the discriminator and generator is performed by the <code>train_discriminator</code> and <code>train_generator</code> methods, respectively. This method coordinates these calls and handles logging and model state saving.
- Progress logging and model saving are designed to provide insights into the training process and to allow for interruption and resumption of training without loss of progress.</p>

          <details class="quote">
            <summary>Source code in <code>trainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Executes the training loop for the Generative Adversarial Network (GAN).</span>

<span class="sd">    This method orchestrates the training process by iterating over a specified number of epochs, during which it trains the discriminator and generator models in sequence. At each step of the training, it logs the progress, including the losses of both models and the discriminator&#39;s performance metrics. At the end of each epoch, it saves the current state of the generator model.</span>

<span class="sd">    The training loop follows these steps:</span>
<span class="sd">    1. Loads the data using the `dataloader` method, which should return an iterable DataLoader object containing the training data.</span>
<span class="sd">    2. Iterates over the specified number of epochs (as defined by `self.num_epochs`).</span>
<span class="sd">        a. For each batch in the DataLoader:</span>
<span class="sd">            i. Trains the discriminator on both real and fake data, computing its loss.</span>
<span class="sd">            ii. Generates a new batch of fake data and trains the generator, attempting to fool the discriminator, computing its loss.</span>
<span class="sd">            iii. Logs the current losses and discriminator performance metrics using the `display_results` method.</span>
<span class="sd">    3. Saves the state of the generator model after each epoch using the `save_generator_model` method.</span>

<span class="sd">    Note:</span>
<span class="sd">    - The actual training of the discriminator and generator is performed by the `train_discriminator` and `train_generator` methods, respectively. This method coordinates these calls and handles logging and model state saving.</span>
<span class="sd">    - Progress logging and model saving are designed to provide insights into the training process and to allow for interruption and resumption of training without loss of progress.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataloader</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">errD</span><span class="p">,</span> <span class="n">D_x</span><span class="p">,</span> <span class="n">D_G_z1</span><span class="p">,</span> <span class="n">fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_discriminator</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">errG</span><span class="p">,</span> <span class="n">D_G_z2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_generator</span><span class="p">(</span><span class="n">fake</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">display_results</span><span class="p">(</span>
                <span class="n">epoch</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">errD</span><span class="p">,</span> <span class="n">errG</span><span class="p">,</span> <span class="n">D_x</span><span class="p">,</span> <span class="n">D_G_z1</span><span class="p">,</span> <span class="n">D_G_z2</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_generator_model</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="trainer.Trainer.train_discriminator" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">train_discriminator</span><span class="p">(</span><span class="n">data</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Trains the discriminator model on both real and generated (fake) images. This method performs a forward pass with real images from the dataset and fake images generated by the generator, computes the loss for both, backpropagates to update the discriminator's weights, and returns the losses and discriminator outputs.</p>
<p>Parameters:
- data (torch.Tensor): A batch of real images from the dataset. This tensor should have the shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and width of the images.</p>
      <ul>
<li>tuple: A tuple containing the following elements:<ul>
<li>errD (torch.Tensor): The total discriminator loss calculated as the sum of the loss for real and fake images.</li>
<li>D_x (float): The mean output of the discriminator for real images. This value is used to evaluate the discriminator's performance on real data.</li>
<li>D_G_z1 (float): The mean output of the discriminator for fake images before the generator update. This value is used to evaluate the discriminator's performance on fake data.</li>
<li>fake (torch.Tensor): A batch of fake images generated by the generator.</li>
</ul>
</li>
</ul>
<p>The method performs the following steps:
1. Zeroes the gradients of the discriminator.
2. Processes a batch of real images, computes the loss against the true labels, backpropagates the error, and calculates the mean discriminator output (D_x).
3. Generates a batch of fake images using the generator, computes the loss against the false labels, backpropagates the error, and calculates the mean discriminator output for the fake images (D_G_z1).
4. Updates the discriminator's weights based on the total loss.</p>
<p>Note:
- This method updates the discriminator's weights once per call, using the combined loss from both real and fake images.
- The real_label and fake_label attributes of the Trainer class are used to denote the true and false labels, respectively, for computing the loss.</p>

          <details class="quote">
            <summary>Source code in <code>trainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train_discriminator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains the discriminator model on both real and generated (fake) images. This method performs a forward pass with real images from the dataset and fake images generated by the generator, computes the loss for both, backpropagates to update the discriminator&#39;s weights, and returns the losses and discriminator outputs.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - data (torch.Tensor): A batch of real images from the dataset. This tensor should have the shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and width of the images.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - tuple: A tuple containing the following elements:</span>
<span class="sd">        - errD (torch.Tensor): The total discriminator loss calculated as the sum of the loss for real and fake images.</span>
<span class="sd">        - D_x (float): The mean output of the discriminator for real images. This value is used to evaluate the discriminator&#39;s performance on real data.</span>
<span class="sd">        - D_G_z1 (float): The mean output of the discriminator for fake images before the generator update. This value is used to evaluate the discriminator&#39;s performance on fake data.</span>
<span class="sd">        - fake (torch.Tensor): A batch of fake images generated by the generator.</span>

<span class="sd">    The method performs the following steps:</span>
<span class="sd">    1. Zeroes the gradients of the discriminator.</span>
<span class="sd">    2. Processes a batch of real images, computes the loss against the true labels, backpropagates the error, and calculates the mean discriminator output (D_x).</span>
<span class="sd">    3. Generates a batch of fake images using the generator, computes the loss against the false labels, backpropagates the error, and calculates the mean discriminator output for the fake images (D_G_z1).</span>
<span class="sd">    4. Updates the discriminator&#39;s weights based on the total loss.</span>

<span class="sd">    Note:</span>
<span class="sd">    - This method updates the discriminator&#39;s weights once per call, using the combined loss from both real and fake images.</span>
<span class="sd">    - The real_label and fake_label attributes of the Trainer class are used to denote the true and false labels, respectively, for computing the loss.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">real_cpu</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_cpu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
        <span class="p">(</span><span class="n">batch_size</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">real_label</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
    <span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">real_cpu</span><span class="p">)</span>
    <span class="n">errD_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">errD_real</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">D_x</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nz</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
    <span class="n">label</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fake_label</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">fake</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
    <span class="n">errD_fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">errD_fake</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">D_G_z1</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">errD</span> <span class="o">=</span> <span class="n">errD_real</span> <span class="o">+</span> <span class="n">errD_fake</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizerD</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">errD</span><span class="p">,</span> <span class="n">D_x</span><span class="p">,</span> <span class="n">D_G_z1</span><span class="p">,</span> <span class="n">fake</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h3 id="trainer.Trainer.train_generator" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">train_generator</span><span class="p">(</span><span class="n">fake</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Trains the generator model by attempting to fool the discriminator.</p>
<p>This method updates the generator's weights based on its ability to generate fake images that the discriminator classifies as real. It computes the loss using the output of the discriminator on the generated (fake) images, performs backpropagation to calculate the gradients, and updates the generator's weights to reduce this loss.</p>
<p>Parameters:
- fake (torch.Tensor): A batch of fake images generated by the generator model. The tensor should have dimensions (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and width of the images, respectively.</p>
      <ul>
<li>tuple: A tuple containing the following elements:<ul>
<li>errG (torch.Tensor): The loss of the generator computed as the binary cross-entropy loss between the discriminator's output on the fake images and the real labels.</li>
<li>D_G_z2 (float): The average output of the discriminator for the fake images. This metric indicates how well the generator is fooling the discriminator, with higher values suggesting better performance.</li>
</ul>
</li>
</ul>
<p>The training step involves:
1. Zeroing the gradients of the generator to ensure that previous training steps do not affect the current update.
2. Creating a tensor of real labels (since the generator's goal is to have its fake images classified as real by the discriminator) and computing the loss against the discriminator's predictions on the fake images.
3. Performing backpropagation to calculate the gradients with respect to the generator's parameters.
4. Updating the generator's weights using the optimizer to reduce the loss, thereby improving the generator's ability to produce realistic images.</p>
<p>Note:
- The method assumes the use of the binary cross-entropy loss (BCELoss) to quantify how well the generator is fooling the discriminator. The labels for the fake images are set to 'real' (self.real_label) for the purpose of this loss calculation.
- This method directly influences the generator's performance by adjusting its ability to create images that are indistinguishable from real images to the discriminator.</p>

          <details class="quote">
            <summary>Source code in <code>trainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fake</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains the generator model by attempting to fool the discriminator.</span>

<span class="sd">    This method updates the generator&#39;s weights based on its ability to generate fake images that the discriminator classifies as real. It computes the loss using the output of the discriminator on the generated (fake) images, performs backpropagation to calculate the gradients, and updates the generator&#39;s weights to reduce this loss.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - fake (torch.Tensor): A batch of fake images generated by the generator model. The tensor should have dimensions (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and width of the images, respectively.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - tuple: A tuple containing the following elements:</span>
<span class="sd">        - errG (torch.Tensor): The loss of the generator computed as the binary cross-entropy loss between the discriminator&#39;s output on the fake images and the real labels.</span>
<span class="sd">        - D_G_z2 (float): The average output of the discriminator for the fake images. This metric indicates how well the generator is fooling the discriminator, with higher values suggesting better performance.</span>

<span class="sd">    The training step involves:</span>
<span class="sd">    1. Zeroing the gradients of the generator to ensure that previous training steps do not affect the current update.</span>
<span class="sd">    2. Creating a tensor of real labels (since the generator&#39;s goal is to have its fake images classified as real by the discriminator) and computing the loss against the discriminator&#39;s predictions on the fake images.</span>
<span class="sd">    3. Performing backpropagation to calculate the gradients with respect to the generator&#39;s parameters.</span>
<span class="sd">    4. Updating the generator&#39;s weights using the optimizer to reduce the loss, thereby improving the generator&#39;s ability to produce realistic images.</span>

<span class="sd">    Note:</span>
<span class="sd">    - The method assumes the use of the binary cross-entropy loss (BCELoss) to quantify how well the generator is fooling the discriminator. The labels for the fake images are set to &#39;real&#39; (self.real_label) for the purpose of this loss calculation.</span>
<span class="sd">    - This method directly influences the generator&#39;s performance by adjusting its ability to create images that are indistinguishable from real images to the discriminator.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">netG</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
        <span class="p">(</span><span class="n">fake</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),),</span> <span class="bp">self</span><span class="o">.</span><span class="n">real_label</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
    <span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netD</span><span class="p">(</span><span class="n">fake</span><span class="p">)</span>
    <span class="n">errG</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">errG</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">D_G_z2</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizerG</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">errG</span><span class="p">,</span> <span class="n">D_G_z2</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>




  </div>

  </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../discriminator/" class="btn btn-neutral float-left" title="Discriminator"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../test/" class="btn btn-neutral float-right" title="Test">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../discriminator/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../test/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>

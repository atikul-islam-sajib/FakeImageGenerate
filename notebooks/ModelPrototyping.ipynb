{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import zipfile\n",
    "import joblib as pickle\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelPrototyping.ipynb  ModelTraining.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def create_pickle(value=None, filename=None):\n",
    "    \"\"\"\n",
    "    Serializes and saves a Python object to a file using pickle.\n",
    "\n",
    "    This function takes a Python object and a filename, and serializes the object to a file with the specified name.\n",
    "    If either the value or the filename is not provided, the function raises an exception.\n",
    "\n",
    "    Parameters:\n",
    "    - value: The Python object to serialize. Must not be None for the operation to proceed.\n",
    "    - filename: The name of the file where the serialized object should be saved. Must not be None for the operation to proceed.\n",
    "\n",
    "    Raises:\n",
    "    - Exception: If either `value` or `filename` is None, indicating incomplete arguments for the operation.\n",
    "    \"\"\"\n",
    "    if value is not None and filename is not None:\n",
    "        with open(filename, \"wb\") as file:\n",
    "            pickle.dump(value, file)\n",
    "    else:\n",
    "        raise Exception(\"Pickle file is empty\".capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif __name__ == \"__main__\":\\n    parser = argparse.ArgumentParser(description=\"Image Preprocessing\".capitalize())\\n    \\n    parser.add_argument(\"--image_path\", help=\"Define the Image path\".capitalize())\\n    parser.add_argument(\"--batch_size\", default=64, type=int, help=\"Define the Batch Size\".capitalize())\\n    parser.add_argument(\"--image_height\", default=64, type=int, help=\"Define the Image Height\".capitalize())\\n    parser.add_argument(\"--image_width\", default=64, type=int, help=\"Define the Image Width\".capitalize())\\n    \\n    args = parser.parse_args()\\n    \\n    if args.image_path is None:\\n        if args.batch_size and args.image_height and args.image_width:\\n            loader = Loader(\\n                image_path=args.image_path,\\n                batch_size=args.batch_size,\\n                image_height=args.image_height,\\n                image_width=args.image_width,\\n                normalized=True,\\n            )\\n            \\n            loader.extract_features()\\n            \\n            dataloader = loader.create_dataloader()\\n            \\n        else:\\n            raise ValueError(\"Please provide the image path\".capitalize())\\n    else:\\n        raise ValueError(\"Please provide the image path\".capitalize())\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Loader:\n",
    "    \"\"\"\n",
    "    A Loader class for processing image datasets. This class is designed to handle the loading,\n",
    "    extracting, and preprocessing of image data from a zip archive, preparing it for machine learning models.\n",
    "\n",
    "    Attributes:\n",
    "        image_path (str, optional): The path to the zip file containing the dataset. Default is None.\n",
    "        batch_size (int): The number of images to process in each batch. Default is 64.\n",
    "        image_height (int): The height to which each image will be resized. Default is 64 pixels.\n",
    "        image_width (int): The width to which each image will be resized. Default is 64 pixels.\n",
    "        normalized (bool): Flag to determine whether the images should be normalized. Default is True.\n",
    "        raw_image_path (str): The path where extracted images are stored. Initially empty.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_path = None, batch_size = 64, image_height = 64, image_width = 64, normalized = True):\n",
    "        \"\"\"\n",
    "        Initializes the Loader with the dataset path, batch size, image dimensions, and normalization flag.\n",
    "        \"\"\"\n",
    "        self.image_path = image_path\n",
    "        self.batch_size = batch_size\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.normalized = normalized\n",
    "        self.raw_image_path = \"\"\n",
    "\n",
    "    def unzip_dataset(self, extract_to = None):\n",
    "        \"\"\"\n",
    "        Extracts the dataset from a zip archive to a specified directory.\n",
    "\n",
    "        Parameters:\n",
    "            extract_to (str): The directory where the zip file contents will be extracted. If None, an exception is raised.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If `extract_to` is None, indicating the path is not properly defined.\n",
    "        \"\"\"\n",
    "        if extract_to is not None:\n",
    "            with zipfile.ZipFile(file=self.image_path, mode=\"r\") as zip_ref:\n",
    "                zip_ref.extractall(path=extract_to)\n",
    "        else:\n",
    "            raise Exception(\"Path is not defined properly in unzip_dataset method\".capitalize())\n",
    "\n",
    "    def extract_features(self,):\n",
    "        \"\"\"\n",
    "        Prepares the dataset by checking for or creating the necessary directories and unzipping the dataset.\n",
    "\n",
    "        This method checks if a raw folder exists for the dataset; if not, it creates one and extracts the dataset there.\n",
    "        \"\"\"\n",
    "        dataset_folder_name = \"../data\"\n",
    "        extract_to = os.path.join(dataset_folder_name, \"raw/\")\n",
    "        if os.path.exists(path = os.path.join(dataset_folder_name, \"raw/\")):\n",
    "            print(\"raw folder already exists\".title())\n",
    "            try:\n",
    "                self.unzip_dataset(extract_to = extract_to)\n",
    "            except Exception as e:\n",
    "                print(\"Error - {}\".format(e))\n",
    "            else:\n",
    "                self.raw_image_path = os.path.join(dataset_folder_name, \"raw/\")\n",
    "        else:\n",
    "            print(\"raw folder does not exists and is about to create\".title())\n",
    "            try:\n",
    "                os.makedirs(os.path.join(dataset_folder_name, \"raw/\"))\n",
    "            except Exception as e:\n",
    "                print(\"Error - {}\".format(e))\n",
    "            else:\n",
    "                self.unzip_dataset(extract_to = extract_to)\n",
    "                self.raw_image_path = os.path.join(dataset_folder_name, \"raw/\")\n",
    "\n",
    "    def saved_dataloader(self, dataloader = None):\n",
    "        \"\"\"\n",
    "        Saves the processed dataloader object to disk.\n",
    "\n",
    "        Parameters:\n",
    "            dataloader: The dataloader object to be saved. If None, an exception is raised.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If `dataloader` is None, indicating it is not properly defined.\n",
    "        \"\"\"\n",
    "        if dataloader is not None:\n",
    "            processed_data_path = \"../data\"\n",
    "            if os.path.exists(os.path.join(processed_data_path, \"processed\")):\n",
    "                try:\n",
    "                    create_pickle(value=dataloader, filename=os.path.join(processed_data_path, \"processed/dataloader.pkl\"))\n",
    "                    print(\"done\")\n",
    "                except Exception as e:\n",
    "                    print(\"Error - {}\".format(e))\n",
    "            else:\n",
    "                print(\"Processed data folder is not exists and is about to create\".capitalize())\n",
    "                os.makedirs(os.path.join(processed_data_path, \"processed\"))\n",
    "                try:\n",
    "                    create_pickle(\n",
    "                        value=dataloader,\n",
    "                        filename=os.path.join(\n",
    "                            processed_data_path, \"processed/dataloader.pkl\"\n",
    "                        ),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(\"Error - {}\".format(e))\n",
    "        else:\n",
    "            raise Exception(\"Dataloader is not defined properly in saved_dataloader method\".capitalize())\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        \"\"\"\n",
    "        Creates a dataloader with the specified transformations and batch size for the dataset.\n",
    "\n",
    "        Returns:\n",
    "            DataLoader: The DataLoader object for the dataset, ready for use in training or evaluation.\n",
    "        \"\"\"\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((self.image_height, self.image_width)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "        dataset = datasets.ImageFolder(root=self.raw_image_path, transform=transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.saved_dataloader(dataloader = dataloader)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Image Preprocessing\".capitalize())\n",
    "    \n",
    "    parser.add_argument(\"--image_path\", help=\"Define the Image path\".capitalize())\n",
    "    parser.add_argument(\"--batch_size\", default=64, type=int, help=\"Define the Batch Size\".capitalize())\n",
    "    parser.add_argument(\"--image_height\", default=64, type=int, help=\"Define the Image Height\".capitalize())\n",
    "    parser.add_argument(\"--image_width\", default=64, type=int, help=\"Define the Image Width\".capitalize())\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.image_path is None:\n",
    "        if args.batch_size and args.image_height and args.image_width:\n",
    "            loader = Loader(\n",
    "                image_path=args.image_path,\n",
    "                batch_size=args.batch_size,\n",
    "                image_height=args.image_height,\n",
    "                image_width=args.image_width,\n",
    "                normalized=True,\n",
    "            )\n",
    "            \n",
    "            loader.extract_features()\n",
    "            \n",
    "            dataloader = loader.create_dataloader()\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Please provide the image path\".capitalize())\n",
    "    else:\n",
    "        raise ValueError(\"Please provide the image path\".capitalize())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "loader = Loader(image_path = \"anime.zip\",\n",
    "                batch_size = 64,\n",
    "                image_height = 64,\n",
    "                image_width = 64,\n",
    "                normalized = True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
